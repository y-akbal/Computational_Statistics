{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb3AtndSJ5vF"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/y-akbal/Tedu_Computational_Statistics/blob/main/6/W6ALE.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mEApmbTYKNBh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import pickle\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buCSNqnDYqDM"
      },
      "source": [
        "# 1) Consider $\\int_0^{0.5} xe^{-x} dx$.\n",
        "# Compute a Monte Carlo estimate $\\hat{\\theta}$ by sampling from $U(0,0.5)$.\n",
        "# Find another Monte Carlo estimate $\\theta^{\\star}$ by sampling from exponential distribution. Which of the variances is smaller? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PmntRApcYpa9"
      },
      "outputs": [],
      "source": [
        "### Graded Cell A1\n",
        "### implement f(x) = xe^{-x}\n",
        "f = lambda x : None ## Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3QTXXXdU9Yi"
      },
      "outputs": [],
      "source": [
        "### Let's give a try:\n",
        "assert f(0) == 0 and np.isclose(np.exp(-1), f(1)) and np.isclose(-np.exp(1), f(-1)), \"Check your implementation mate\"\n",
        "print(\"You are doin' good buddy go ahed\")\n",
        "L = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S0L9wT6KVce-"
      },
      "outputs": [],
      "source": [
        "### Graded Cell A2\n",
        "### Now let's do Monte Carlo Integration with arguments n_sample (set it default 1000) and f:\n",
        "### f should a tuple with first argument as the approximate value of the integral and the variance of the integral\n",
        "def monte_carlo(f: Callable, n_sample = 1000, seed = 10)-> tuple:\n",
        "  np.random.seed(seed) ### this is for reproducability, do not delete it!!!\n",
        "  ### Your code here\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRbBxf09XCuD"
      },
      "outputs": [],
      "source": [
        "### Let's give a try:\n",
        "test = lambda x: x\n",
        "assert callable(monte_carlo), \"No way check your implementation 0\"\n",
        "assert np.isclose(monte_carlo(test)[0], 0.125, atol = 0.01), \" Check your implementation 1\"\n",
        "assert np.isclose(monte_carlo(f)[0], 0.09, atol = 0.01),  \" Check your implementation 2\"\n",
        "assert np.isclose(monte_carlo(f)[1], 0.007, atol = 0.1), \"Check your implementation 3 (in particular variance)\"\n",
        "print(\"You are doin' good buddy go ahead!!!\")\n",
        "L_ = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJTfSnmmYbcx"
      },
      "source": [
        "## If you have come this far you are done with the first part!!! Now lets go to the second part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ppVU8dLpYaij"
      },
      "outputs": [],
      "source": [
        "### Directly implemenet integration by means of sampling from exponential distribution\n",
        "### Graded Cell A26\n",
        "### the function should return a tuple as mean and variance\n",
        "def integration_expo(n_sample = 100, seed = 10)-> tuple:\n",
        "  np.random.seed(10) ### this is for reproducability, do not delete it!!!\n",
        "  ### Your code here\n",
        "  return None ### mean, variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QKv0Zj0emUj"
      },
      "outputs": [],
      "source": [
        "### Let's give it a try:\n",
        "assert callable(integration_expo), \"No way check your implementation 0\"\n",
        "assert np.isclose(integration_expo()[0], 0.09, atol = 0.1), \" Check your implementation 1\"\n",
        "assert np.isclose(integration_expo()[1], 0.02, atol = 0.1), \"Check your implementation 2 (in particular variance)\"\n",
        "print(\"You are doin' good buddy go ahead!!!\")\n",
        "L__ = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhtjBXAzgV_w"
      },
      "outputs": [],
      "source": [
        "### Graded Cell A15:\n",
        "### Run this cell and get your freedom.\n",
        "def set_answer():\n",
        "  global L___\n",
        "  while True:\n",
        "    res = input(\"Which sampling method has lesser variance? (First or Second):\")\n",
        "    if res == \"First\":\n",
        "      L___ = True\n",
        "      print(\"Yeaaah you got it right buddy\")\n",
        "      break\n",
        "    elif res == \"Second\":\n",
        "      L___ = False\n",
        "      break\n",
        "    else:\n",
        "      print(\"Either write First or Second\")\n",
        "set_answer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI6npyIWfoCi"
      },
      "outputs": [],
      "source": [
        "def final_check():\n",
        "  x = int(L+L_+L__+ L___)\n",
        "  if x == 4:\n",
        "    print(\"Congrats comrade!!! You passed this assignment\")\n",
        "  else:\n",
        "    print(\"Comrade do not stop now!!! check your implementations\")\n",
        "  return \n",
        "final_check()  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
